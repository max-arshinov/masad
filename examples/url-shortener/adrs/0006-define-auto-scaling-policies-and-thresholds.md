# 6. Define Auto-scaling Policies and Thresholds

Date: 2025-09-01

## Status

Proposed

## Context

Iteration 1 goal: Address high-risk performance and scalability concerns. Growth projections show read RPS growing from 11.5K (year 1) to 139K (year 5), with 3x peak traffic spikes reaching 417K RPS. System must maintain P-1 latency during traffic surges while managing costs efficiently.

Business drivers: Handle unpredictable traffic patterns, maintain service quality during peak loads, optimize operational costs.

Relevant QAs (IDs): P-1 (redirect latency <0.2s), P-3 (<0.1s degradation with failures), A-1 (99.9% uptime), S-3 (10 requests/link/day).

## Decision

### Table 1 â€” Compare Auto-scaling Approaches

| Scaling Approach | Response Time | Accuracy | Cost Efficiency | Complexity | Overshoot Risk | Undershoot Risk |
|------------------|---------------|----------|-----------------|------------|----------------|-----------------|
| **Reactive (CPU/Memory)** | ðŸŸ¨ 3-5 min delay | ðŸŸ¨ lagging indicator | ðŸŸ© resource-based | ðŸŸ© simple | ðŸŸ¨ moderate | ðŸŸ¥ high during spikes |
| **Predictive (ML-based)** | ðŸŸ© proactive | ðŸŸ¨ depends on patterns | ðŸŸ¨ may over-provision | ðŸŸ¥ complex models | ðŸŸ¨ pattern changes | ðŸŸ© anticipates load |
| **Application Metrics (RPS)** | ðŸŸ© traffic-responsive | ðŸŸ© direct correlation | ðŸŸ© load-proportional | ðŸŸ¨ custom metrics | ðŸŸ© low | ðŸŸ¨ burst handling |
| **Queue Depth Based** | ðŸŸ© backpressure-aware | ðŸŸ© processing capacity | ðŸŸ© workload-aligned | ðŸŸ¨ requires queuing | ðŸŸ© low | ðŸŸ© low |
| **Hybrid (Multi-metric)** | ðŸŒŸ fastest response | ðŸŒŸ comprehensive view | ðŸŸ¨ balanced approach | ðŸŸ¥ complex logic | ðŸŸ© weighted decisions | ðŸŸ© multiple signals |

**Shortlist:** Application Metrics (RPS) and Hybrid approaches best address P-1 requirements and traffic spike handling.

### Table 2 â€” Compare Auto-scaling Platforms

| Platform | Scaling Speed | Metric Support | Geographic Scaling | Integration | Cost Model | Monitoring |
|----------|---------------|----------------|-------------------|-------------|------------|------------|
| **AWS Auto Scaling** | ðŸŸ© 1-3 min warmup | ðŸŸ© CloudWatch + custom | ðŸŸ© multi-region ASGs | ðŸŒŸ native AWS | ðŸŸ© instance-based | ðŸŸ© CloudWatch |
| **Kubernetes HPA/VPA** | ðŸŸ© pod-level scaling | ðŸŸ© custom metrics API | ðŸŸ¨ cluster federation | ðŸŸ© cloud-agnostic | ðŸŸ¨ cluster overhead | ðŸŸ© Prometheus |
| **Google Cloud Autoscaler** | ðŸŸ© managed scaling | ðŸŸ© Stackdriver metrics | ðŸŸ© regional MIGs | ðŸŸ© GCP native | ðŸŸ© usage-based | ðŸŸ© Stackdriver |
| **Azure VMSS** | ðŸŸ¨ slower warmup | ðŸŸ¨ Azure Monitor | ðŸŸ¨ availability zones | ðŸŸ¨ Azure ecosystem | ðŸŸ¨ VM-based | ðŸŸ¨ Azure Monitor |

**Decision:** Implement hybrid auto-scaling using AWS Auto Scaling Groups with multi-metric policies:

Primary metrics:
- RPS per instance (target: 5,000 RPS, scale-out threshold: 4,000 RPS)
- Average response time (target: <150ms, scale-out threshold: >180ms)
- CPU utilization (scale-out threshold: >70%, scale-in threshold: <30%)

Scaling policies:
- Scale-out: Add 50% capacity when any threshold breached
- Scale-in: Remove 25% capacity when all metrics below targets for 10 minutes
- Regional scaling: Deploy across 3 AZs with minimum 2 instances per AZ
- Cross-region: Route53 health checks trigger regional failover

Supersedes: none.

## Consequences

- âœ… Maintains P-1 latency during traffic spikes with proactive RPS-based scaling
- âœ… Addresses RISK-PEAK-TRAFFIC with 50% capacity scaling and multi-region deployment
- âœ… Provides P-3 fault tolerance with multi-AZ and cross-region redundancy
- âœ… Supports projected 417K peak RPS with horizontal scaling across regions
- âš ï¸ Requires careful tuning of scale-in policies to avoid thrashing
- âš ï¸ Cold start latency impact during rapid scale-out events
- Follow-ups: ADR on instance warming strategies, cost optimization policies, monitoring dashboards
