# 9. Define Analytics and Click Tracking Architecture

Date: 2025-09-01

## Status

Proposed

## Context

Iteration 2 goal: Database Architecture and Data Management. System must achieve 100% click tracking with real-time analytics capabilities while handling 100M links/year generating ~1B click events annually. Analytics must support both real-time dashboards and historical reporting across 3-year retention period.

Business drivers: Complete click tracking for business intelligence, real-time monitoring, user analytics, performance optimization insights.

Relevant QAs (IDs): M-1 (100% click tracking), S-2 (100M links/year), R-1 (3-year data retention).

## Decision

### Table 1 â€” Compare Analytics Architectures

| Architecture Pattern | Real-time Capability | Scalability | Data Consistency | Query Flexibility | Operational Complexity | Cost Efficiency |
|---------------------|-------------------|-------------|------------------|------------------|----------------------|----------------|
| **Synchronous (Direct DB)** | ğŸŸ© immediate | ğŸŸ¨ limited by DB | ğŸŒŸ strong consistency | ğŸŸ© full SQL | ğŸŸ© simple | ğŸŸ¨ expensive scaling |
| **Asynchronous (Message Queue)** | ğŸŸ¨ near real-time | ğŸŸ© horizontal scaling | ğŸŸ¨ eventual consistency | ğŸŸ© flexible processing | ğŸŸ¨ queue management | ğŸŸ© cost-effective |
| **Event Streaming (Kafka)** | ğŸŒŸ real-time streams | ğŸŒŸ massive scale | ğŸŸ¨ eventual consistency | ğŸŒŸ stream processing | ğŸŸ¥ complex operations | ğŸŸ¨ infrastructure cost |
| **Hybrid (Sync + Async)** | ğŸŸ© immediate + batch | ğŸŸ© scalable analytics | ğŸŸ© configurable | ğŸŒŸ multi-pattern | ğŸŸ¥ dual complexity | ğŸŸ¨ balanced cost |
| **CQRS (Command/Query Split)** | ğŸŸ© optimized reads | ğŸŸ© independent scaling | ğŸŸ¨ eventual consistency | ğŸŒŸ specialized stores | ğŸŸ¥ complex sync | ğŸŸ¨ dual storage |

**Shortlist:** Asynchronous (Message Queue) and Event Streaming (Kafka) best address M-1 reliability and S-2 scale requirements.

### Table 2 â€” Compare Analytics Storage Solutions

| Storage Solution | Write Throughput | Query Performance | Real-time Analytics | Historical Analysis | Operational Overhead | Integration |
|------------------|------------------|-------------------|-------------------|-------------------|---------------------|-------------|
| **PostgreSQL (OLTP)** | ğŸŸ¨ 10K writes/sec | ğŸŸ¨ row-based queries | ğŸŸ¨ basic aggregation | ğŸŸ¨ limited OLAP | ğŸŸ© familiar | ğŸŒŸ native |
| **ClickHouse** | ğŸŒŸ 1M+ writes/sec | ğŸŒŸ columnar OLAP | ğŸŸ© materialized views | ğŸŒŸ time-series analysis | ğŸŸ¨ specialized ops | ğŸŸ¨ external |
| **Amazon Redshift** | ğŸŸ© 100K writes/sec | ğŸŸ© columnar warehouse | ğŸŸ¨ batch updates | ğŸŒŸ historical OLAP | ğŸŸ© managed | ğŸŸ¨ ETL required |
| **Elasticsearch** | ğŸŸ© high ingestion | ğŸŸ© search + aggregation | ğŸŸ© near real-time | ğŸŸ¨ time-based retention | ğŸŸ¨ cluster management | ğŸŸ¨ external |
| **Amazon Timestream** | ğŸŸ© time-series optimized | ğŸŸ© time-based queries | ğŸŸ© real-time ingestion | ğŸŸ© automatic retention | ğŸŒŸ serverless | ğŸŸ¨ AWS native |

**Decision:** Implement event-driven analytics using Amazon Kinesis + ClickHouse architecture:

**Click Tracking Pipeline:**
- Synchronous click recording to PostgreSQL for immediate redirect tracking
- Asynchronous event streaming via Amazon Kinesis Data Streams
- Real-time analytics ingestion to ClickHouse for OLAP workloads
- Kinesis Data Firehose for S3 archival (compliance with retention policy)

**Analytics Architecture:**
- ClickHouse cluster for real-time dashboards and time-series analytics
- Materialized views for pre-computed metrics (daily/hourly aggregations)
- PostgreSQL read replicas for operational analytics and ad-hoc queries
- S3 + Amazon Athena for historical analysis (24+ months old data)

**Event Schema:**
```json
{
  "click_id": "uuid",
  "short_url": "string",
  "original_url": "string", 
  "timestamp": "iso8601",
  "user_agent": "string",
  "ip_address": "string",
  "referer": "string",
  "geo_location": "object"
}
```

**Processing Guarantees:**
- At-least-once delivery via Kinesis with deduplication in ClickHouse
- Dead letter queues for failed events
- Circuit breaker pattern for analytics pipeline failures

Supersedes: none.

## Consequences

- âœ… Achieves M-1 with dual-write pattern ensuring 100% click tracking
- âœ… Supports S-2 scale with Kinesis handling 1M+ events/second throughput
- âœ… Enables real-time analytics for business intelligence and monitoring
- âœ… Complies with R-1 through S3 archival integration
- âš ï¸ Eventual consistency between operational and analytical stores
- âš ï¸ Increased operational complexity with multiple data systems
- Follow-ups: ADR on event schema evolution, ClickHouse cluster sizing, monitoring and alerting for analytics pipeline
