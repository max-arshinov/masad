# 11. Select Caching Architecture

Date: 2025-09-03

## Status

Proposed

## Context

Iteration goal: Design caching architecture to support 100K concurrent analysts while maintaining sub-1.5s query response times and ensuring query consistency across the multi-tier aggregation strategy established in ADR-010.

Business drivers: Analytics platform must serve repeated queries efficiently while balancing cache hit rates with data freshness. Common usage patterns include dashboard refreshes, repeated report views, and exploratory analysis with similar parameters.

Relevant QAs (IDs): P-1 Performance (Report response time â‰¤1.5s), P-3 Performance (100K concurrent users), R-2 Reliability (Query consistency), S-2 Scalability (Storage capacity).

## Decision

### Compare **Cache Types**

| Cache Type            | Hit Rate Potential   | Consistency Model   | Implementation     | Memory Efficiency  | Network Overhead   | TTL Management     |
|-----------------------|----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|
| **Query Result Cache**| ğŸŸ© high for dashboards| ğŸŸ¨ time-based TTL | ğŸŸ© application layer| ğŸŸ¨ full results   | ğŸŸ© reduced DB calls| ğŸŸ¨ complex expiry  |
| **Aggregation Cache** | ğŸŒŸ very high        | ğŸŸ© data-driven     | ğŸŸ¨ DB layer        | ğŸŸ© compressed aggs | ğŸŸ© minimal        | ğŸŸ© event-based     |
| **Connection Pool**   | ğŸŸ¨ connection reuse  | ğŸŒŸ transparent     | ğŸŸ© simple          | ğŸŸ© minimal memory  | ğŸŸ© reduced setup   | ğŸŸ© automatic       |
| **CDN Edge Cache**    | ğŸŸ© geographic       | ğŸŸ¨ eventual        | ğŸŸ¨ edge deployment | ğŸŸ© distributed    | ğŸŒŸ edge delivery   | ğŸŸ¨ global sync     |

### Compare **Cache Technologies**

| Technology            | Throughput           | Latency             | Clustering         | Memory Efficiency  | Operational Model  | Analytics Features |
|-----------------------|----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|
| **Redis Cluster**     | ğŸŸ© high ops/sec     | ğŸŒŸ <1ms            | ğŸŸ© native sharding | ğŸŸ© efficient      | ğŸŸ¨ manual setup    | ğŸŸ¨ basic types     |
| **Amazon ElastiCache**| ğŸŸ© managed scaling  | ğŸŸ© low latency     | ğŸŸ© managed cluster | ğŸŸ© optimized      | ğŸŒŸ serverless      | ğŸŸ¨ Redis/Memcached |
| **Hazelcast**         | ğŸŸ© distributed      | ğŸŸ© in-memory       | ğŸŸ© automatic       | ğŸŸ© near-cache      | ğŸŸ¨ complex config  | ğŸŸ© compute grid    |
| **Application Cache** | ğŸŸ¨ single-node      | ğŸŒŸ zero network    | ğŸŸ¥ no clustering   | ğŸŸ¨ heap limited    | ğŸŸ© simple          | ğŸŸ© custom logic    |
| **ClickHouse Cache**  | ğŸŸ© query-optimized  | ğŸŸ© columnar        | ğŸŸ© distributed     | ğŸŒŸ compressed      | ğŸŸ© built-in        | ğŸŒŸ SQL-aware       |

**Decision:** Implement **hybrid caching architecture** with three cache layers:

**Layer 1 - Application Cache (In-Memory):**
- Cache frequent dashboard queries and user session data
- 15-minute TTL for real-time aggregates, 4-hour TTL for historical data
- Ehcache or Caffeine for JVM applications

**Layer 2 - Distributed Cache (Redis Cluster):**
- Cache expensive aggregation results and query metadata
- Cross-application sharing for 100K concurrent users
- 1-hour TTL with event-driven invalidation

**Layer 3 - Database Query Cache (ClickHouse):**
- Built-in query result caching for repeated SQL patterns
- Automatic invalidation based on data freshness
- Native compression and distributed storage

Supersedes: none.

## Consequences

- âœ… Sub-1.5s response times through multi-layer cache hits for 80%+ of queries (P-1).
- âœ… Horizontal scaling of cache capacity supports 100K concurrent users (P-3).
- âœ… Consistent cache invalidation maintains data accuracy across aggregation tiers (R-2).
- âœ… Memory-efficient storage through compressed aggregates and smart TTL policies.
- âœ… Reduced database load enables better resource utilization (S-2).
- âš ï¸ Cache consistency complexity across three layers requires careful coordination.
- âš ï¸ Memory overhead for application and distributed caches needs monitoring.
- Follow-ups: ADR-012 (read replica topology), cache warming strategies, invalidation event design.
