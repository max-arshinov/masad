# 14. Design Batch Processing Strategy

Date: 2025-09-03

## Status

Proposed

## Context

Iteration goal: Design batch processing strategy to complement Kafka Streams for complex aggregations and historical data processing while maintaining 50-100min processing latency SLA and zero data loss guarantees.

Business drivers: Analytics platform requires both real-time stream processing for immediate aggregations and batch processing for complex multi-dimensional aggregations, historical reprocessing, and data quality validation across large time windows.

Relevant QAs (IDs): A-1 Availability (Data processing latency within 50-100min), R-1 Reliability (Zero data loss), S-1 Scalability (Event volume growth), P-2 Performance (High event ingestion throughput).

## Decision

### Compare **Batch Processing Patterns**

| Pattern               | Processing Latency   | Resource Efficiency | Fault Recovery     | Data Consistency   | Operational Model  | Cost Structure     |
|-----------------------|----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|
| **Scheduled ETL**     | ğŸŸ¨ fixed intervals  | ğŸŸ© predictable     | ğŸŸ¨ job-level retry | ğŸŸ© batch boundaries| ğŸŸ© mature tooling | ğŸŸ© scheduled resources|
| **Event-Driven**      | ğŸŸ© triggered processing| ğŸŸ¨ variable load  | ğŸŸ© granular retry  | ğŸŸ¨ eventual       | ğŸŸ¨ complex orchestration| ğŸŸ¨ elastic costs  |
| **Lambda Architecture**| ğŸŸ¨ dual processing  | ğŸŸ¥ resource duplication| ğŸŸ© path redundancy| ğŸŸ¨ merge complexity| ğŸŸ¥ dual maintenance| ğŸŸ¥ high overhead   |
| **Hybrid Stream-Batch**| ğŸŸ© adaptive        | ğŸŸ© workload optimization| ğŸŸ© multi-level   | ğŸŸ© configurable   | ğŸŸ¨ coordination   | ğŸŸ© optimized      |

### Compare **Batch Processing Technologies**

| Technology            | Data Volume Capacity | Processing Speed    | Resource Management| Integration        | Monitoring         | Cost Efficiency    |
|-----------------------|----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|
| **Apache Spark**      | ğŸŒŸ petabyte scale   | ğŸŸ© in-memory       | ğŸŸ© dynamic allocation| ğŸŸ© broad ecosystem| ğŸŸ© comprehensive   | ğŸŸ© cluster sharing |
| **AWS EMR**           | ğŸŒŸ elastic capacity | ğŸŸ© managed Spark   | ğŸŒŸ auto-scaling   | ğŸŒŸ AWS native     | ğŸŸ© CloudWatch      | ğŸŸ© pay-per-use    |
| **AWS Glue**          | ğŸŸ© serverless scale | ğŸŸ¨ Python/Scala    | ğŸŒŸ serverless     | ğŸŒŸ data catalog   | ğŸŸ© built-in       | ğŸŒŸ serverless      |
| **Airflow + Workers** | ğŸŸ¨ depends on workers| ğŸŸ¨ task-based      | ğŸŸ¨ manual scaling  | ğŸŸ© flexible       | ğŸŸ© rich UI        | ğŸŸ¨ infrastructure mgmt|
| **ClickHouse MaterializedViews**| ğŸŸ© columnar efficiency| ğŸŒŸ real-time    | ğŸŸ© automatic      | ğŸŒŸ native DB      | ğŸŸ¨ basic          | ğŸŒŸ included       |

**Decision:** Implement **hybrid stream-batch architecture** using:

**Real-time Layer (Kafka Streams):**
- Simple aggregations (counts, sums) with 1-minute windows
- Direct writes to ClickHouse for immediate dashboard updates
- Covers 80% of analytics queries requiring <5min latency

**Batch Layer (AWS EMR with Spark):**
- Complex multi-dimensional aggregations every 15 minutes
- Historical reprocessing and data quality validation
- Covers remaining 20% of queries requiring complex analytics

**Coordination:**
- EMR jobs triggered by Kafka lag monitoring
- Incremental processing based on event timestamps
- Idempotent operations for safe reprocessing

Supersedes: none.

## Consequences

- âœ… 15-minute batch cycles ensure 50-100min processing SLA with multiple retry attempts (A-1).
- âœ… Dual processing paths provide fault tolerance and zero data loss guarantees (R-1).
- âœ… EMR auto-scaling handles event volume growth from 1.16M to 1.7M events/sec (S-1, P-2).
- âœ… Cost optimization through serverless batch processing and cluster auto-termination.
- âœ… Separation of concerns: stream for latency, batch for complexity.
- âš ï¸ Coordination complexity between stream and batch processing requires monitoring.
- âš ï¸ Data consistency windows during batch processing transitions.
- Follow-ups: ADR-015 (validation across both layers), ADR-016 (backup for both processing paths).
