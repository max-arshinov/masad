# 13. Choose Stream Processing Framework

Date: 2025-09-03

## Status

Proposed

## Context

Iteration goal: Select stream processing framework to ensure events appear in analytics reports within 50-100 minutes while handling 1.16M events/sec sustained throughput and maintaining zero data loss during processing.

Business drivers: Analytics platform requires real-time data pipeline to transform raw events into aggregated data for ClickHouse storage. Processing must scale with event volume growth to 146B events/day by year 5 while maintaining data consistency.

Relevant QAs (IDs): A-1 Availability (Data processing latency within 50-100min), R-1 Reliability (Zero data loss), S-1 Scalability (Event volume growth), P-2 Performance (High event ingestion throughput).

## Decision

### Compare **Stream Processing Paradigms**

| Paradigm              | Processing Latency   | Fault Tolerance     | Scalability         | Operational Model  | State Management   | Exactly-Once Delivery|
|-----------------------|----------------------|---------------------|---------------------|--------------------|--------------------|----------------------|
| **Micro-batch**       | ğŸŸ¨ seconds to minutes| ğŸŸ© checkpoint recovery| ğŸŸ© horizontal     | ğŸŸ© mature tooling  | ğŸŸ© distributed    | ğŸŸ© built-in         |
| **True Streaming**    | ğŸŒŸ milliseconds     | ğŸŸ© message replay  | ğŸŸ© elastic         | ğŸŸ¨ complex setup   | ğŸŸ¨ in-memory      | ğŸŸ¨ complex config   |
| **Lambda Architecture**| ğŸŸ¨ dual path       | ğŸŸ© redundant paths  | ğŸŸ© independent     | ğŸŸ¥ operational overhead| ğŸŸ¨ dual state   | ğŸŸ¨ eventual consistency|
| **Serverless**        | ğŸŸ© auto-scaling    | ğŸŸ© managed         | ğŸŒŸ infinite        | ğŸŒŸ no ops         | ğŸŸ¨ limited        | ğŸŸ© managed          |

### Compare **Stream Processing Technologies**

| Technology            | Throughput           | Latency             | Fault Tolerance    | Operational Complexity| Ecosystem         | AWS Integration    |
|-----------------------|----------------------|---------------------|--------------------|-----------------------|-------------------|--------------------|
| **Apache Kafka Streams**| ğŸŸ© millions/sec   | ğŸŸ© low latency     | ğŸŸ© exactly-once    | ğŸŸ¨ library-based     | ğŸŸ© Kafka native   | ğŸŸ¨ self-managed    |
| **Apache Flink**      | ğŸŒŸ very high        | ğŸŒŸ true streaming   | ğŸŒŸ advanced checkpointing| ğŸŸ¥ complex ops    | ğŸŸ© rich features  | ğŸŸ¨ deployment overhead|
| **Apache Spark Streaming**| ğŸŸ© high throughput| ğŸŸ¨ micro-batch     | ğŸŸ© RDD lineage     | ğŸŸ© mature ecosystem  | ğŸŒŸ extensive      | ğŸŸ© EMR integration |
| **Amazon Kinesis Analytics**| ğŸŸ¨ moderate     | ğŸŸ© real-time       | ğŸŸ© managed         | ğŸŒŸ serverless        | ğŸŸ¨ SQL-based      | ğŸŒŸ native AWS      |
| **AWS Lambda + Kinesis**| ğŸŸ¨ event-driven   | ğŸŸ© near real-time  | ğŸŸ© auto-retry      | ğŸŸ© minimal ops       | ğŸŸ© serverless     | ğŸŒŸ native AWS      |

**Decision:** Select **Apache Kafka Streams** as the primary stream processing framework. Kafka Streams provides native integration with the MSK infrastructure established in ADR-006, enabling exactly-once processing semantics for zero data loss while maintaining sub-minute processing latency. The library-based approach reduces operational overhead compared to cluster-based solutions while providing sufficient throughput for 1.16M+ events/sec.

Supersedes: none.

## Consequences

- âœ… Sub-minute processing latency enables 50-100min analytics SLA with buffer for aggregation (A-1).
- âœ… Exactly-once semantics prevents data loss during stream processing transformations (R-1).
- âœ… Horizontal scaling through Kafka partitions supports event volume growth (S-1, P-2).
- âœ… Native MSK integration reduces operational complexity and network overhead.
- âœ… Stateful processing capabilities enable complex aggregations and windowing operations.
- âš ï¸ Library-based deployment requires application lifecycle management vs managed services.
- âš ï¸ Java/Scala expertise needed for stream topology development and optimization.
- Follow-ups: ADR-014 (batch processing for complex aggregations), ADR-015 (data validation), ADR-016 (backup procedures).
