# 5. Choose Event Ingestion Architecture Pattern

Date: 2025-09-03

## Status

Proposed

## Context

Iteration goal: Design high-volume data ingestion architecture to handle 100B events/day capacity requirement with sustained 1.16M events/sec and peak loads up to 3.47M events/sec by year 1, scaling to 146B events/day by year 5.

Business drivers: Analytics platform must ingest massive event volumes from websites (page views, clicks) while ensuring zero data loss and maintaining system availability during traffic spikes up to 3x daily average.

Relevant QAs (IDs): P-2 Performance (High event ingestion throughput), S-1 Scalability (Event volume growth), R-1 Reliability (Data durability), A-2 Availability (System uptime).

## Decision

### Compare **Ingestion Patterns**

| Pattern                | Throughput           | Fault Tolerance     | Scalability         | Complexity         | Data Durability     | Backpressure Handling |
|------------------------|----------------------|---------------------|---------------------|--------------------|--------------------|----------------------|
| **Direct Write**       | ğŸŸ¨ limited by DB    | ğŸŸ¥ single point    | ğŸŸ¥ vertical only   | ğŸŸ© simple         | ğŸŸ¨ depends on DB   | ğŸŸ¥ poor             |
| **Message Queue**      | ğŸŸ© high via buffering| ğŸŸ© queue durability| ğŸŸ© horizontal      | ğŸŸ¨ moderate        | ğŸŸ© persistent queue| ğŸŸ© excellent        |
| **Event Streaming**    | ğŸŒŸ very high        | ğŸŸ© partitioned     | ğŸŒŸ elastic         | ğŸŸ¨ moderate        | ğŸŸ© replicated logs | ğŸŸ© excellent        |
| **Batch Collection**   | ğŸŸ© high throughput  | ğŸŸ¨ batch loss risk | ğŸŸ¨ scale with delay| ğŸŸ© simple         | ğŸŸ¨ batch boundaries| ğŸŸ¨ delayed          |

### Compare **Technologies**

| Technology         | Peak Throughput    | Durability         | Operational Complexity | Cost Efficiency | Ecosystem         | Multi-Region      |
|--------------------|--------------------|--------------------|------------------------|-----------------|-------------------|-------------------|
| **Apache Kafka**   | ğŸŒŸ millions/sec    | ğŸŸ© replicated logs | ğŸŸ¨ cluster mgmt        | ğŸŸ© open source  | ğŸŒŸ rich ecosystem | ğŸŸ© native support |
| **AWS Kinesis**    | ğŸŸ© 1M records/sec  | ğŸŸ© managed         | ğŸŸ© serverless          | ğŸŸ¨ usage-based  | ğŸŸ© AWS integrated | ğŸŸ© managed        |
| **Google Pub/Sub** | ğŸŸ© high throughput | ğŸŸ© managed         | ğŸŸ© serverless          | ğŸŸ¨ usage-based  | ğŸŸ© GCP integrated | ğŸŸ© global         |
| **RabbitMQ**       | ğŸŸ¨ moderate        | ğŸŸ© durable queues  | ğŸŸ¨ cluster setup       | ğŸŸ© open source  | ğŸŸ¨ traditional    | ğŸŸ¨ manual setup   |
| **Amazon SQS**     | ğŸŸ¨ 300K msgs/sec   | ğŸŸ© managed         | ğŸŸ© serverless          | ğŸŸ© pay per use  | ğŸŸ© AWS ecosystem  | ğŸŸ© global         |

**Decision:** Adopt **Event Streaming with Apache Kafka** as the primary ingestion pattern. Kafka's partitioned, replicated log architecture provides the throughput (millions of events/sec), horizontal scalability, and fault tolerance required for 1.16M+ sustained writes and 3.47M peak loads. The streaming model enables real-time processing while maintaining durability through configurable replication.

Supersedes: none.

## Consequences

- âœ… Handles peak ingestion loads (P-2) with horizontal partitioning and producer scaling (S-1).
- âœ… Zero data loss through configurable replication and acknowledgment policies (R-1).
- âœ… High availability during traffic spikes via partition redundancy (A-2).
- âœ… Decouples ingestion from processing, enabling independent scaling of consumers.
- âš ï¸ Requires Kafka cluster operational expertise and monitoring.
- âš ï¸ Additional complexity for schema evolution and message ordering guarantees.
- Follow-ups: ADR-006 (Kafka deployment strategy), ADR-007 (partitioning strategy), ADR-008 (auto-scaling policies).
